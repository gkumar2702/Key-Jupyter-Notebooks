{"cells": [{"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Import Required packages**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "import os\nimport math\nimport warnings\nimport operator\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\n\nfrom pandas.io import gbq\nfrom datetime import date, timedelta\nfrom datetime import datetime\nfrom google.cloud import storage\nfrom IPython.display import display, HTML\n\nwarnings.filterwarnings('ignore')\npd.options.mode.chained_assignment = None  # default='warn'\n\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 2000)\npd.options.display.float_format = '{:.2f}'.format"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Read OMS Dark-sky curated dataset**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "bucket_name = 'gs://aes-datahub-0002-curated/Outage_Restoration/Live_Data_Curation/'\ndf_omsds = pd.read_csv(bucket_name + 'Dark-sky/OMS_Dark-sky_Live_Data.csv')\ndf_omsds = df_omsds.loc[:, ~df_omsds.columns.str.contains('^Unnamed')]"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Read Storm Profiles Data**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "df_omsds['CREATION_DATETIME'] = pd.to_datetime(df_omsds['CREATION_DATETIME'],errors='coerce')\ndf_omsds['Date'] = df_omsds['CREATION_DATETIME'].dt.date\n\nunique_dates = df_omsds[['Date']]\nunique_dates.drop_duplicates(subset=['Date'], keep='first', inplace=True)\nunique_dates['Date'] = unique_dates['Date'].apply(lambda x: x.strftime('%Y%m%d'))\nunique = unique_dates['Date'].to_list()\nprint(unique)\n\n\nstorm_profiles_location = 'gs://aes-datahub-0002-curated/Outage_Restoration/Live_Data_Curation/Storm_Profiles/'\n# storm_profiles_location = 'gs://aes-datahub-0001-curated/Outage_Restoration/Live_Data_Curation/Storm_Profiles/storm_profiles_20200622.csv'\nstorm_profiles_files = [] \n\nfor i in unique:         \n    filename = storm_profiles_location + 'storm_profiles_{}.csv'.format(i)         \n    print(filename)         \n    storm_profiles_files.append(pd.read_csv(filename))\n\nstormprofiles_df = pd.read_csv(storm_profiles_location)\n\nstormprofiles_df = pd.concat(storm_profiles_files)\nstormprofiles_df.reset_index(drop=True, inplace=True)\nstormprofiles_df = stormprofiles_df.loc[:, ~stormprofiles_df.columns.str.contains('^Unnamed')]"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Storm Profiles Weather Data Cleaning**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "stormprofiles_df=stormprofiles_df[['Date', 'Location', 'clusters']]\nstormprofiles_df['Date']=pd.to_datetime(stormprofiles_df['Date'])\ndf_omsds['Date']=pd.to_datetime(df_omsds['Date'])\nprint(stormprofiles_df.shape)"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "df_omsds['Date'] = pd.to_datetime(df_omsds['Date'])\ndf_omsds = df_omsds.merge(stormprofiles_df,how='left',left_on=['Date','Marker_Location'],right_on=['Date','Location'])"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Change all columns to Flag values**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "flg_list = list(df_omsds.filter(regex='FLG').columns)\nprior_list = list(df_omsds.filter(regex='PRIORITY').columns)\nfinal_list = flg_list + prior_list\nmapin = { 1: 'True', 0: 'False'}\nfor i in final_list:\n    df_omsds[i] = df_omsds[i].map(mapin)"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "## **Read output dataset and filter for Predicted Flag**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "try:\n    df_pred = 'SELECT OUTAGE_ID FROM aes-analytics-0002.mds_outage_restoration.IPL_LIVE_PREDICTIONS'\n    df_pred = gbq.read_gbq(df_pred, project_id = \"aes-analytics-0002\")\n    df_pred['PREDICTED_FLG'] = 1\n    df_joined=pd.merge(df_omsds,df_pred,on=['OUTAGE_ID'],how='left')\n    df_final=df_joined[pd.isnull(df_joined['PREDICTED_FLG'])][df_omsds.columns]\n    \nexcept:\n    df_final=df_omsds\n "}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "df_final.fillna(method='ffill', inplace=True)"}, {"cell_type": "markdown", "metadata": {"Collapsed": "false"}, "source": "# **Write curated dataset to Big query table**"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "df_final.to_gbq('mds_outage_restoration.IPL_Live_Master_Dataset', project_id = 'aes-analytics-0002',\n                chunksize=None, reauth=False, if_exists='replace', auth_local_webserver=False, table_schema=None,\n                location=None, progress_bar=True, credentials=None)"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": "# Backup\ndf_final.to_csv(\"gs://aes-datahub-0002-curated/Outage_Restoration/Historical_Data/BQ_backup/IPL_OMS_LIVE_Data.csv\")"}, {"cell_type": "code", "execution_count": null, "metadata": {"Collapsed": "false"}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.3"}}, "nbformat": 4, "nbformat_minor": 4}