{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['20200923']\ngs://aes-analytics-0002-curated/Outage_Restoration/Live_Data_Curation/Storm_Profiles_ws/storm_profiles_20200923.csv\n(20, 4)\n"}, {"ename": "Exception", "evalue": "No new Outages, All outages are already predicted for", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-1-a611348e6066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No new Outages, All outages are already predicted for'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# # **Write curated dataset to Big query table**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mException\u001b[0m: No new Outages, All outages are already predicted for"]}], "source": "\n######################################################################################################################################################################################################\n######################################################################### Curated Data Set creation####################################################################################\n######################################################################################################################################################################################################\n\n#!/usr/bin/env python\n# coding: utf-8\n\n# # **Import Required packages**\n\n# In[ ]:\n\n\nimport os\nimport math\nimport warnings\nimport operator\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom datetime import datetime\nfrom pandas.io import gbq\nfrom datetime import date, timedelta\nfrom datetime import datetime\nfrom google.cloud import storage\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import SparkSession\n\nwarnings.filterwarnings('ignore')\npd.options.mode.chained_assignment = None  # default='warn'\n\nimport logging\nlogging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)\nsc = SparkContext.getOrCreate()\nspark = SparkSession(sc)\n\n\n# # **Read OMS Dark-sky curated dataset**\n\n# In[ ]:\n\n\nbucket_name = 'gs://aes-analytics-0002-curated/Outage_Restoration/Live_Data_Curation/'\n\ndf_omsds=spark.read.format('CSV').option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\").load(\n    bucket_name + 'weather-source/OMS_weather-source_Live_Data.csv').toPandas()\n#df_omsds = df_omsds.loc[:, ~df_omsds.columns.str.contains('^Unnamed')]\n\n\n# # **Read Storm Profiles Data**\n\n# In[ ]:\n\n\ndf_omsds['CREATION_DATETIME'] = pd.to_datetime(df_omsds['CREATION_DATETIME'],errors='coerce')\ndf_omsds['Date'] = df_omsds['CREATION_DATETIME'].dt.date\n\nunique_dates = df_omsds[['Date']]\nunique_dates.drop_duplicates(subset=['Date'], keep='first', inplace=True)\nunique_dates['Date'] = unique_dates['Date'].apply(lambda x: x.strftime('%Y%m%d'))\nunique = unique_dates['Date'].to_list()\nprint(unique)\n\n\nstorm_profiles_location = 'gs://aes-analytics-0002-curated/Outage_Restoration/Live_Data_Curation/Storm_Profiles_ws/'\nstorm_profiles_files = [] \n\nfor i in unique:         \n    filename = storm_profiles_location + 'storm_profiles_{}.csv'.format(i)         \n    print(filename)         \n    storm_profiles_files.append(pd.read_csv(filename))\n\nstormprofiles_df = spark.read.format('CSV').option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\").load(\n    storm_profiles_location).toPandas()\n\nstormprofiles_df = pd.concat(storm_profiles_files)\nstormprofiles_df.reset_index(drop=True, inplace=True)\nstormprofiles_df = stormprofiles_df.loc[:, ~stormprofiles_df.columns.str.contains('^Unnamed')]\n\n\n# # **Storm Profiles Weather Data Cleaning**\n\n# In[ ]:\n\n\nstormprofiles_df=stormprofiles_df[['timestamp', 'Location', 'clusters']]\nstormprofiles_df['Date']=pd.to_datetime(stormprofiles_df['timestamp']).dt.date\ndf_omsds['Date']=pd.to_datetime(df_omsds['Date'])\nprint(stormprofiles_df.shape)\n\n\n# In[ ]:\n\n\ndf_omsds['Date'] = pd.to_datetime(df_omsds['Date']).dt.date\ndf_omsds = df_omsds.merge(stormprofiles_df,how='left',left_on=['Date','Marker_Location'],right_on=['Date','Location'])\ndf_omsds.drop(['timestamp_y','timestamp_x'],axis=1,inplace=True)\n\n\n# ## **Read output dataset and filter for Predicted Flag**\n\n# In[ ]:\n\n\ntry:    \n    df_pred = 'SELECT OUTAGE_ID FROM aes-analytics-0002.mds_outage_restoration.IPL_PREDICTIONS_ws'\n    df_pred = gbq.read_gbq(df_pred, project_id = \"aes-analytics-0002\")\n    predictions=list(df_pred['OUTAGE_ID'].unique())\n    df_omsds['OUTAGE_ID'] = df_omsds['OUTAGE_ID'].astype(str)\n    df_omsds['OUTAGE_ID']=df_omsds['OUTAGE_ID'].str.replace(' ','')\n    df_final=df_omsds[~df_omsds['OUTAGE_ID'].isin(predictions)]\n    df_final.reset_index(drop=True,inplace=True)\n    \nexcept:\n    df_final=df_omsds\n\nshape = df_final.shape[0]\nif (shape==0):\n    raise Exception('No new Outages, All outages are already predicted for')\n\n# # **Write curated dataset to Big query table**\n\n# In[ ]:\nif 'DOWNSTREAM_CUST_QTY' not in df_final:\n    df_final['DOWNSTREAM_CUST_QTY']=df_final['CUST_QTY']\n\n\ndf_final['KVA_VAL']=df_final['DOWNSTREAM_KVA_VAL']\n\n# **Change all columns to Flag values**\n\n# In[ ]:\n\n\n# flg_list = list(df_final.filter(regex='FLG').columns)\n# day_flg_list = list(df_final.filter(regex='FLAG').columns)\n# prior_list = list(df_final.filter(regex='PRIORITY').columns)\n# final_list = flg_list + prior_list+day_flg_list\n# mapin = { 1: 'TRUE', 0: 'FALSE'}\n# for i in final_list:\n#     df_final[i] = df_final[i].map(mapin)\n\n# df_final.fillna(method='ffill',inplace=True)\n# df_final['CITY_NAM'].fillna('NO_CITY',inplace=True)\n\n# df_final = df_final.loc[:, ~df_final.columns.str.contains('^Unnamed')]\n# In[ ]:\n# df_final.to_csv(\"gs://aes-analytics-0002-curated/Outage_Restoration/Staging/IPL_Live_Master_Dataset_ws.csv\",index=False)\n# # Backup\n# df_final.to_csv(\"gs://aes-analytics-0002-curated/Outage_Restoration/Historical_Data/BQ_backup/IPL_OMS_LIVE_Data_\"+datetime.today().strftime('%Y%m%d%H%M')+\".csv\",index=False)"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "df_final=df_omsds"}, {"cell_type": "markdown", "metadata": {}, "source": "## **ADD NO OF OUTAGES FOR CLUE, CAUSE, OCCURN**"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>NO_OF_POWER_OUT_CLUE_PER_DAY</th>\n      <th>NO_OF_OPEN_DEVICE_CLUE_PER_DAY</th>\n      <th>NO_OF_IVR_CLUE_PER_DAY</th>\n      <th>NO_OF_ANIMAL_CAUSE_PER_DAY</th>\n      <th>NO_OF_WIRE_OCCURN_PER_DAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-09-23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         Date  NO_OF_POWER_OUT_CLUE_PER_DAY  NO_OF_OPEN_DEVICE_CLUE_PER_DAY  \\\n0  2020-09-23                             0                               0   \n\n   NO_OF_IVR_CLUE_PER_DAY  NO_OF_ANIMAL_CAUSE_PER_DAY  \\\n0                       0                           0   \n\n   NO_OF_WIRE_OCCURN_PER_DAY  \n0                          0  "}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "df_final['CREATION_DATETIME'] = pd.to_datetime(df_final['CREATION_DATETIME'])\ndf_final['Date'] = df_final['CREATION_DATETIME'].dt.date\n\ndf_no_of_outages = df_final.groupby(['Date'],as_index=False).agg({'POWER_OUT_CLUE_FLG' : 'sum', 'OPEN_DEVICE_CLUE_FLG' : 'sum', 'IVR_CLUE_FLG' : 'sum', 'ANIMAL_CAUSE_FLG' : 'sum',\n                                                                'WIRE_OCCURN_FLG' : 'sum'})\ndf_no_of_outages.rename(columns = {'POWER_OUT_CLUE_FLG' : 'NO_OF_POWER_OUT_CLUE_PER_DAY', 'OPEN_DEVICE_CLUE_FLG' : 'NO_OF_OPEN_DEVICE_CLUE_PER_DAY',\n                                   'IVR_CLUE_FLG' : 'NO_OF_IVR_CLUE_PER_DAY', 'ANIMAL_CAUSE_FLG' : 'NO_OF_ANIMAL_CAUSE_PER_DAY',\n                                   'WIRE_OCCURN_FLG' : 'NO_OF_WIRE_OCCURN_PER_DAY'}, inplace=True)\n\ndf_no_of_outages.head()"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "try:\n    df_clue_count=pd.read_csv('gs://aes-analytics-0002-curated/Outage_Restoration/Staging/OMS_Clue_Flag_Record.csv')\nexcept:\n    df_no_of_outages.to_csv('gs://aes-analytics-0002-curated/Outage_Restoration/Staging/OMS_Clue_Flag_Record.csv',index=False)"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "record_date=(datetime.today()-timedelta(days=1)).date()"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "df_clue_count['Date']=pd.to_datetime(df_clue_count.Date).dt.date\ndf_clue_count_current=df_clue_count[df_clue_count.Date>=record_date]"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>NO_OF_POWER_OUT_CLUE_PER_DAY</th>\n      <th>NO_OF_OPEN_DEVICE_CLUE_PER_DAY</th>\n      <th>NO_OF_IVR_CLUE_PER_DAY</th>\n      <th>NO_OF_ANIMAL_CAUSE_PER_DAY</th>\n      <th>NO_OF_WIRE_OCCURN_PER_DAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2020-09-24</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         Date  NO_OF_POWER_OUT_CLUE_PER_DAY  NO_OF_OPEN_DEVICE_CLUE_PER_DAY  \\\n1  2020-09-24                             1                               0   \n\n   NO_OF_IVR_CLUE_PER_DAY  NO_OF_ANIMAL_CAUSE_PER_DAY  \\\n1                       0                           0   \n\n   NO_OF_WIRE_OCCURN_PER_DAY  \n1                          0  "}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df_clue_count_current"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "df_clue_count=df_clue_count.append(df_no_of_outages)"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "df_clue_count = df_clue_count.groupby(['Date'],as_index=False).agg({'NO_OF_POWER_OUT_CLUE_PER_DAY' : 'sum', 'NO_OF_OPEN_DEVICE_CLUE_PER_DAY' : 'sum', 'NO_OF_IVR_CLUE_PER_DAY' : 'sum', 'NO_OF_ANIMAL_CAUSE_PER_DAY' : 'sum',\n                                                                'NO_OF_WIRE_OCCURN_PER_DAY' : 'sum'})"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>NO_OF_POWER_OUT_CLUE_PER_DAY</th>\n      <th>NO_OF_OPEN_DEVICE_CLUE_PER_DAY</th>\n      <th>NO_OF_IVR_CLUE_PER_DAY</th>\n      <th>NO_OF_ANIMAL_CAUSE_PER_DAY</th>\n      <th>NO_OF_WIRE_OCCURN_PER_DAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-09-23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-09-24</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         Date  NO_OF_POWER_OUT_CLUE_PER_DAY  NO_OF_OPEN_DEVICE_CLUE_PER_DAY  \\\n0  2020-09-23                             0                               0   \n1  2020-09-24                             1                               0   \n\n   NO_OF_IVR_CLUE_PER_DAY  NO_OF_ANIMAL_CAUSE_PER_DAY  \\\n0                       0                           0   \n1                       0                           0   \n\n   NO_OF_WIRE_OCCURN_PER_DAY  \n0                          0  \n1                          0  "}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "df_clue_countto_csv('gs://aes-analytics-0002-curated/Outage_Restoration/Staging/OMS_Clue_Flag_Record.csv',index=False)"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "df_final = df_final.merge(df_clue_count,how='left',left_on=['Date'],right_on=['Date'])"}, {"cell_type": "markdown", "metadata": {}, "source": "## **OUTAGE FEATURES**"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": "try:    \n    df_pred_outages = 'SELECT OUTAGE_ID,Creation_Time FROM aes-analytics-0002.mds_outage_restoration.IPL_PREDICTIONS_ws where creation_time>='+\"'\"+str(record_date)+\"'\"\n    df_pred_outages = gbq.read_gbq(df_pred_outages, project_id = \"aes-analytics-0002\")\n    df_pred_outages.reset_index(drop=True,inplace=True)\nexcept:\n    df_pred_outages=pd.DataFrame()"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": "df_pred_outages['CREATION_DATETIME']=pd.to_datetime(df_pred_outages.Creation_Time)\ndf_pred_outages.drop(['Creation_Time'],axis=1,inplace=True)"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": "df_final_outage_count=df_final[['OUTAGE_ID','CREATION_DATETIME']]\ndf_final_outage_count=df_final_outage_count.append(df_pred_outages)\ndf_final_outage_count.reset_index(inplace=True)"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "2020-09-25 11:55:30,655 NumExpr defaulting to 8 threads.\n"}], "source": "def count_outage_minutes(group):\n    group = group.reset_index(drop = True)\n    df_temp = df_final_outage_count[['OUTAGE_ID','CREATION_DATETIME']]\n    df_temp['minutes'] = (group['CREATION_DATETIME'][0] - df_final_outage_count['CREATION_DATETIME']).dt.total_seconds().div(60)\n    df_temp = df_temp[df_temp.minutes > 0]\n    group['Outages_in_last_1hr'] = len(df_temp[df_temp.minutes <= 60])\n    group['Outages_in_last_2hr'] = len(df_temp[df_temp.minutes <= 120])\n    group['Outages_in_last_3hr'] = len(df_temp[df_temp.minutes <= 180])\n    group['Outages_in_last_4hr'] = len(df_temp[df_temp.minutes <= 240])\n    group['Outages_in_last_5hr'] = len(df_temp[df_temp.minutes <= 300])\n    group['Outages_in_last_6hr'] = len(df_temp[df_temp.minutes <= 360])\n    group['Outages_in_last_7hr'] = len(df_temp[df_temp.minutes <= 420])\n    group['Outages_in_last_8hr'] = len(df_temp[df_temp.minutes <= 480])\n    group['Outages_in_last_9hr'] = len(df_temp[df_temp.minutes <= 540])\n    group['Outages_in_last_10hr'] = len(df_temp[df_temp.minutes <= 600])\n    return group\n\ndef grouping_fn_minutes(df):\n    liveoutage = df.groupby(['OUTAGE_ID'], as_index=False).apply(count_outage_minutes)\n    return liveoutage\nlive_outages=grouping_fn_minutes(df_final)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outages_in_last_1hr</th>\n      <th>Outages_in_last_2hr</th>\n      <th>Outages_in_last_3hr</th>\n      <th>Outages_in_last_4hr</th>\n      <th>Outages_in_last_5hr</th>\n      <th>Outages_in_last_6hr</th>\n      <th>Outages_in_last_7hr</th>\n      <th>Outages_in_last_8hr</th>\n      <th>Outages_in_last_9hr</th>\n      <th>Outages_in_last_10hr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   Outages_in_last_1hr  Outages_in_last_2hr  Outages_in_last_3hr  \\\n0                    0                    0                    0   \n\n   Outages_in_last_4hr  Outages_in_last_5hr  Outages_in_last_6hr  \\\n0                    0                    0                    0   \n\n   Outages_in_last_7hr  Outages_in_last_8hr  Outages_in_last_9hr  \\\n0                    0                    0                    0   \n\n   Outages_in_last_10hr  \n0                     0  "}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "live_outages[[ 'Outages_in_last_1hr',\n 'Outages_in_last_2hr',\n 'Outages_in_last_3hr',\n 'Outages_in_last_4hr',\n 'Outages_in_last_5hr',\n 'Outages_in_last_6hr',\n 'Outages_in_last_7hr',\n 'Outages_in_last_8hr',\n 'Outages_in_last_9hr',\n 'Outages_in_last_10hr']]"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INCIDENT_ID</th>\n      <th>STRCTUR_NO</th>\n      <th>CIRCT_ID</th>\n      <th>DNI_EQUIP_TYPE</th>\n      <th>CALL_QTY</th>\n      <th>CUST_QTY</th>\n      <th>KVA_VAL</th>\n      <th>DOWNSTREAM_KVA_VAL</th>\n      <th>INCIDENT_DEVICE_ID</th>\n      <th>CREATION_DATETIME</th>\n      <th>...</th>\n      <th>windSpd100mMax</th>\n      <th>wetBulbMin</th>\n      <th>wetBulbAvg</th>\n      <th>wetBulbMax</th>\n      <th>WIND_DIRECTION</th>\n      <th>SEASON</th>\n      <th>weekend_flag</th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>clusters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001543646</td>\n      <td>321WA/155</td>\n      <td>1207</td>\n      <td>SB_FUSE</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>175.0</td>\n      <td>2002750725</td>\n      <td>2020-09-23 17:17:36+00:00</td>\n      <td>...</td>\n      <td>15.4</td>\n      <td>54.7</td>\n      <td>58.2</td>\n      <td>62.3</td>\n      <td>S-W-W</td>\n      <td>SUMMER</td>\n      <td>0</td>\n      <td>2020-09-23</td>\n      <td>Marker 6</td>\n      <td>Cluster1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows \u00d7 147 columns</p>\n</div>", "text/plain": "   INCIDENT_ID STRCTUR_NO  CIRCT_ID DNI_EQUIP_TYPE  CALL_QTY  CUST_QTY  \\\n0   2001543646  321WA/155      1207        SB_FUSE         2         3   \n\n   KVA_VAL  DOWNSTREAM_KVA_VAL  INCIDENT_DEVICE_ID         CREATION_DATETIME  \\\n0      0.0               175.0          2002750725 2020-09-23 17:17:36+00:00   \n\n   ...  windSpd100mMax  wetBulbMin  wetBulbAvg wetBulbMax  WIND_DIRECTION  \\\n0  ...            15.4        54.7        58.2       62.3           S-W-W   \n\n   SEASON  weekend_flag        Date  Location  clusters  \n0  SUMMER             0  2020-09-23  Marker 6  Cluster1  \n\n[1 rows x 147 columns]"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "df_omsds"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Uninstalling google-cloud-bigquery-1.27.2:\n  Successfully uninstalled google-cloud-bigquery-1.27.2\nCollecting google-cloud-bigquery==1.26.0\n  Downloading https://files.pythonhosted.org/packages/39/6d/6846ba302c751f72767003b0fc0bf89d43a78fe7fe4149ed6d1b635eb052/google_cloud_bigquery-1.26.0-py2.py3-none-any.whl (170kB)\nRequirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery==1.26.0) (1.4.1)\nRequirement already satisfied: google-api-core<2.0dev,>=1.21.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery==1.26.0) (1.22.2)\nRequirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery==1.26.0) (1.15.0)\nCollecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-bigquery==1.26.0)\n  Downloading https://files.pythonhosted.org/packages/f2/cc/cd05c633298fcbba5d61b6b8844de598e001954281a004fc1a13c61a5121/google_resumable_media-0.5.1-py2.py3-none-any.whl\nRequirement already satisfied: setuptools>=34.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (41.4.0)\nRequirement already satisfied: protobuf>=3.12.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (3.13.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (1.52.0)\nRequirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (1.21.1)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (2.24.0)\nRequirement already satisfied: pytz in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (2019.3)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (4.1.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (1.24.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (2020.6.20)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery==1.26.0) (0.4.8)\nInstalling collected packages: google-resumable-media, google-cloud-bigquery\n  Found existing installation: google-resumable-media 1.0.0\n    Uninstalling google-resumable-media-1.0.0:\n      Successfully uninstalled google-resumable-media-1.0.0\nSuccessfully installed google-cloud-bigquery-1.26.0 google-resumable-media-0.5.1\nCollecting google-cloud-bigquery-storage\n  Downloading https://files.pythonhosted.org/packages/42/9a/003822d79a535472c089ca39fb384b74b8a3624f4d5a1715c4c52059418d/google_cloud_bigquery_storage-1.1.0-py2.py3-none-any.whl (135kB)\nRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery-storage) (1.22.2)\nRequirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (1.21.1)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (2.24.0)\nRequirement already satisfied: protobuf>=3.12.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (3.13.0)\nRequirement already satisfied: pytz in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (2019.3)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (1.52.0)\nRequirement already satisfied: setuptools>=34.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (41.4.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (1.15.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (1.31.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (4.1.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (1.24.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (2.8)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-bigquery-storage) (0.4.8)\nInstalling collected packages: google-cloud-bigquery-storage\nSuccessfully installed google-cloud-bigquery-storage-1.1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "ERROR: google-cloud-storage 1.31.0 has requirement google-resumable-media<2.0dev,>=1.0.0, but you'll have google-resumable-media 0.5.1 which is incompatible.\nERROR: fairing 0.5.3 has requirement tornado<6.0.0,>=5.1.1, but you'll have tornado 6.0.3 which is incompatible.\n"}], "source": "%%sh\npip uninstall google-cloud-bigquery --y\nhttp_proxy=http://10.245.5.249:8080\nexport http_proxy\nhttps_proxy=https://10.245.5.249:8080\nexport https_proxy\npip install google-cloud-bigquery==1.26.0\npip install google-cloud-bigquery-storage"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_omsds[df_omsds.isnull().any(axis=1)]"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}